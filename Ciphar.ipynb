{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVAPZv4CAj7d",
        "outputId": "c3581bba-9933-446a-a1fb-a56d950d54e8"
      },
      "id": "bVAPZv4CAj7d",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "40ea2dca",
      "metadata": {
        "id": "40ea2dca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "2acd045d",
      "metadata": {
        "scrolled": true,
        "id": "2acd045d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pickle\n",
        "CIFAR_DIR='/content/drive/MyDrive/data/cifar-10-batches-py/'\n",
        "\n",
        "def unpickle(file):\n",
        "    \n",
        "    with open(file,'rb') as fo:\n",
        "        cifar_dict=pickle.load(fo,encoding='bytes')\n",
        "    return cifar_dict\n",
        "\n",
        "\n",
        "dirs=['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']\n",
        "\n",
        "all_data=[0,1,2,3,4,5,6]\n",
        "for i,direc in zip(all_data,dirs):\n",
        "    all_data[i]=unpickle(CIFAR_DIR+direc)\n",
        "meta=all_data[0]\n",
        "batch1=all_data[1]\n",
        "batch2=all_data[2]\n",
        "batch3=all_data[3]\n",
        "batch4=all_data[4]\n",
        "batch5=all_data[5]\n",
        "test_batch=all_data[6]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "12abc15e",
      "metadata": {
        "id": "12abc15e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "X=batch1[b\"data\"]\n",
        "# (X[0].shape) =(3072,)\n",
        "# 3072=3*32*32, in which 3 is number of color channel, 32 *32 is image size. For illustration, refer this link:\n",
        "# https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c\n",
        "X=X.reshape(10000,3,32,32).transpose(0,2,3,1).astype(\"uint8\")\n",
        "Y=batch1[b\"labels\"]\n",
        "#  e.g. Y[0] =6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "87032bae",
      "metadata": {
        "id": "87032bae"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(vec,vals=10):\n",
        "    n=len(vec)\n",
        "    out=np.zeros((n,vals))\n",
        "    out[range(n),vec]=1\n",
        "    return out\n",
        "\n",
        "#  E.g : print (one_hot_encode(np.array([2,3])))\n",
        "# [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
        "#  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "186eb74f",
      "metadata": {
        "id": "186eb74f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# e.g. of np.vstack :\n",
        "# a=np.array([1,1,1])\n",
        "# b=np.array([2,2,2])\n",
        "# c=np.array([3,3,3])\n",
        "# print (np.vstack([a,b,c]))\n",
        "# [[1 1 1]\n",
        "#  [2 2 2]\n",
        "#  [3 3 3]]\n",
        "\n",
        "# e.g. of np.hstack\n",
        "# a = np.array((1,2,3))\n",
        "# b = np.array((4,5,6))\n",
        "# np.hstack((a,b))\n",
        "# array([1, 2, 3, 4, 5, 6])\n",
        "# a = np.array([[1],[2],[3]])\n",
        "# b = np.array([[4],[5],[6]])\n",
        "# np.hstack((a,b))\n",
        "# array([[1, 4],\n",
        "#        [2, 5],\n",
        "#        [3, 6]])\n",
        "class Helper():\n",
        "    def __init__(self):\n",
        "\n",
        "        self.i=0\n",
        "        #    i is variable used for batch iteration?\n",
        "        self.all_train_batches=[batch1,batch2,batch3,batch4,batch5]\n",
        "        self.test_batches=[test_batch]\n",
        "        self.training_images=None\n",
        "        self.training_labels=None\n",
        "        self.test_images=None\n",
        "        self.test_labels=None\n",
        "    def set_up(self):\n",
        "        a=np.array([1,1,1])\n",
        "        b=np.array([2,2,2])\n",
        "        c=np.array([3,3,3])\n",
        "# # Here we reshape and transpose since Convnet receives the input in shape (width, height, color channel) and divide by 225 so that the value is within (0,1)\n",
        "        \n",
        "        self.training_images=np.vstack([d[b\"data\"] for d in self.all_train_batches])\n",
        "        train_len=len(self.training_images)\n",
        "        self.training_images=self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
        "        self.training_labels=one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches] ),10)\n",
        "        \n",
        "        self.test_images=np.vstack([d[b\"data\"] for d in self.test_batches])\n",
        "        train_len=len(self.test_images)\n",
        "        self.test_images=self.test_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
        "        self.test_labels=one_hot_encode(np.hstack([d[b\"labels\"] for d in self.test_batches] ),10)\n",
        "    def next_batch (self,batch_size):\n",
        "        x=self.training_images[self.i:self.i+batch_size].reshape(100,32,32,3)\n",
        "        y=self.training_labels[self.i:self.i+batch_size]\n",
        "        self.i=(self.i+batch_size)%len(self.training_images)\n",
        "        return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "4e067720",
      "metadata": {
        "id": "4e067720"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "tf.disable_v2_behavior() \n",
        "helper=Helper()\n",
        "helper.set_up()\n",
        "\n",
        "x=tf.placeholder(tf.float32,shape=[None,32,32,3])\n",
        "y_true=tf.placeholder(tf.float32,shape=[None,10])\n",
        "hold_prob=tf.placeholder(tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "83346ecc",
      "metadata": {
        "id": "83346ecc"
      },
      "outputs": [],
      "source": [
        "def init_weights(shape):\n",
        "    random_dist=tf.truncated_normal(shape,stddev=0.1)\n",
        "    return tf.Variable(random_dist)\n",
        "def init_bias(shape):\n",
        "    init_bias_vals=tf.constant(0.1,shape=shape)\n",
        "    return tf.Variable(init_bias_vals)\n",
        "def conv2d(x,W):\n",
        "    x = tf.cast(x, tf.float32)\n",
        "#     W  is filter/kernel, which usuallly has shape of 4,\n",
        "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
        "def max_pool_2by2(x):\n",
        "    x = tf.cast(x, tf.float32)\n",
        "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "def convolutional_layer(input_x,shape):\n",
        "    W=init_weights(shape)\n",
        "#     for convo_1 shape [4,4,3,32], shape b will be 32\n",
        "# after convolution, we get a*b*C,then activation would be Wx+b would have shape out-channel, here b is 32\n",
        "\n",
        "\n",
        "    b=init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x,W)+b)\n",
        "def normal_full_layer(input_layer,size):\n",
        "#     size is 1024 in case full_layer below, \n",
        "    input_size=int(input_layer.get_shape()[1])\n",
        "#     e.g, input size of convo_2_pooling is 8*8*64\n",
        "    W=init_weights([input_size,size])\n",
        "#     shape W :(4096 1024)\n",
        "    b=init_bias([size])\n",
        "    return tf.matmul(input_layer,W)+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "462a91f9",
      "metadata": {
        "id": "462a91f9"
      },
      "outputs": [],
      "source": [
        "# here [4,4,3,32] is shape of kernel\n",
        "# [4,4 is kernel width and height]\n",
        "# 3 is kernel channel in\n",
        "# 32 is kernel channel out\n",
        "# shape x : (N 32 32 3)\n",
        "\n",
        "convo_1=convolutional_layer(x,shape=[4,4,3,32])\n",
        "# shape convo_1: (N 32 32 32)\n",
        "convo_1_pooling=max_pool_2by2(convo_1)\n",
        "# shape convo_1: (N 16 16 32)\n",
        "convo_2=convolutional_layer(convo_1_pooling,shape=[4,4,32,64])\n",
        "# shape convo_2 : (N 16 16 64)\n",
        "convo_2_pooling=max_pool_2by2(convo_2)\n",
        "# shape convo_2_pooling : (N 8 8 64)\n",
        "#  -1 let the tf calculate the shape for us\n",
        "convo_2_flat=tf.reshape(convo_2_pooling,[-1,8*8*64])\n",
        "full_layer_one=tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n",
        "full_one_dropout=tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\n",
        "# normal_full_layer  predicts the result in the last layer ,which 10 is number  label \n",
        "y_pred=normal_full_layer(full_one_dropout,10)\n",
        "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))\n",
        "\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate=0.0017)\n",
        "train=optimizer.minimize(cross_entropy)\n",
        "init=tf.global_variables_initializer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "e035e1db",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e035e1db",
        "outputId": "e6a3353e-d2d3-4f3d-8a90-6926ba5394d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on step0\n",
            "Accuracy :\n",
            "0.1014\n",
            "\n",
            "\n",
            "on step100\n",
            "Accuracy :\n",
            "0.3716\n",
            "\n",
            "\n",
            "on step200\n",
            "Accuracy :\n",
            "0.4277\n",
            "\n",
            "\n",
            "on step300\n",
            "Accuracy :\n",
            "0.4744\n",
            "\n",
            "\n",
            "on step400\n",
            "Accuracy :\n",
            "0.4942\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for i in range (500):\n",
        "        batch=helper.next_batch(100)\n",
        "    \n",
        "       \n",
        "        sess.run(train,feed_dict={x:batch[0],y_true:batch[1],hold_prob:0.5})\n",
        "        if i%100==0:\n",
        "            print('on step{}'.format (i))\n",
        "            print('Accuracy :')\n",
        "            matches=tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "            acc=tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "            print (sess.run(acc,feed_dict={x:helper.test_images,y_true:helper.test_labels,hold_prob:0.5}))\n",
        "            print ('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "3f173695",
      "metadata": {
        "id": "3f173695"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}